{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c30cf5e0fa8be4ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f084ab2f7cf453d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_samples(dataset, split, seed):\n",
    "    np.random.seed(seed)\n",
    "    print(f\"Plot Samples (seed = {seed}, {split} split)\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    found_samples = {i: False for i in range(8)}\n",
    "    \n",
    "    while not all(found_samples.values()):\n",
    "        idx = np.random.randint(0, len(dataset))\n",
    "        image , label = dataset[idx]\n",
    "        if found_samples[label]:\n",
    "            continue\n",
    "        # Plot the image\n",
    "        plt.subplot(2, 4, label + 1)\n",
    "        plt.imshow(image.squeeze().permute(1, 2, 0))\n",
    "        plt.title(f'Label: {label}')\n",
    "        plt.axis('off')\n",
    "        found_samples[label] = True\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_label_distribution_histogram(dataset, split):\n",
    "    labels = [label for _, label in dataset]\n",
    "\n",
    "    counts = [labels.count(i) for i in range(8)]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(range(8), counts)\n",
    "\n",
    "    for i in range(8):\n",
    "        ax.text(i, counts[i], f\"{100*(counts[i]/sum(counts)):.1f} %\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    ax.set_xlabel(\"Label\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xticks(range(8))\n",
    "    ax.set_xticklabels(range(8), ha=\"center\")\n",
    "    ax.set_title(f\"Histogram of labels distribution for {split} split\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89fbbcc57315fb35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Prepare datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a577cb20ac5aac5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"dataset/TRAIN\"\n",
    "TUNE_DATA_PATH = \"dataset/TUNE\"\n",
    "TRAIN_SPLIT_OF_ALL = 0.8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b547f4bb6454d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scale = torchvision.transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "transforms_augment = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=20), \n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    scale,\n",
    "])\n",
    "transforms_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    scale,\n",
    "])\n",
    "\n",
    "train_valid_dataset = ImageFolder(\n",
    "    root=TRAIN_DATA_PATH,\n",
    "    transform=transforms_augment,\n",
    ")\n",
    "tune_dataset = ImageFolder(\n",
    "    root=TUNE_DATA_PATH,\n",
    "    transform=transforms_norm,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35db714c29e7a79f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explore datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d27958beb9629d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_samples(\n",
    "    dataset=train_valid_dataset, \n",
    "    split=\"train+valid\", \n",
    "    seed=21,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c99c31cbf2723c86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_label_distribution_histogram(\n",
    "    dataset=train_valid_dataset, \n",
    "    split=\"train+valid\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d03b2d787b4973b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_label_distribution_histogram(\n",
    "    dataset=tune_dataset, \n",
    "    split=\"tune\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8df13ff927c3c584"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split train-validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3880ec6aacda31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [sample[1] for sample in train_valid_dataset]\n",
    "\n",
    "train_dataset, valid_dataset = train_test_split(\n",
    "    train_valid_dataset,\n",
    "    train_size=TRAIN_SPLIT_OF_ALL,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8e7c50f2c9562c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_label_distribution_histogram(\n",
    "    dataset=train_dataset, \n",
    "    split=\"train\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f88750aa9ed65e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_label_distribution_histogram(\n",
    "    dataset=valid_dataset, \n",
    "    split=\"valid\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8d31cc7470d419"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create data loaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3822f62f1033e668"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset)\n",
    "valid_loader = DataLoader(valid_dataset)\n",
    "Tune_loader = DataLoader(tune_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "969ed49cf9d4ad46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a97e6fdc575003"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa17108405e534c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Eval helpers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2e93bd7e430b394"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_eval(model, loader, loss_function=nn.CrossEntropyLoss(), device=\"auto\"):\n",
    "    \"\"\"Returns test_loss, test_accuracy\"\"\"\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    sample_count = 0\n",
    "    if device == \"auto\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    itr = tqdm(loader, total=len(loader), leave=False)\n",
    "\n",
    "    for inputs, labels in itr:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        sample_count += np.shape(inputs)[0]\n",
    "\n",
    "        itr.set_description(\"(Evaluation)\")\n",
    "        itr.set_postfix(loss=round(loss.item(), 5), accuracy=round(test_correct/sample_count, 2))\n",
    "\n",
    "    test_loss = test_loss / len(loader)\n",
    "    test_acc = test_correct / sample_count\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        batch_size,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "        epochs,\n",
    "        train_set,\n",
    "        test_set=None,\n",
    "        device=\"auto\",\n",
    "):\n",
    "    \"\"\"\n",
    "    If test_set is not None, it would evaluate model for each epoch,\n",
    "    train_set would be in N*(img, logit , label) and N*(img, label) format.\n",
    "    \"\"\"\n",
    "    if device == \"auto\":\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    needs_test_evaluation = test_set is not None\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "\n",
    "    test_loss_list = None if test_set is None else []\n",
    "    test_acc_list = None if test_set is None else []\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    if needs_test_evaluation:\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        samples_count = 0\n",
    "        itr = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "\n",
    "        for inputs, *target_set in itr:\n",
    "            samples_count += np.shape(inputs)[0]\n",
    "            inputs = inputs.to(device)\n",
    "            targets = target_set[0].to(device)\n",
    "            if len(target_set) == 2:\n",
    "                labels = target_set[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels).item()\n",
    "\n",
    "            itr.set_description(f\"(Training) Epoch [{epoch + 1}/{epochs}]\")\n",
    "            itr.set_postfix(loss=round(loss.item(), 5), accuracy=round(train_correct/samples_count, 3))\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / len(train_set)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "        if needs_test_evaluation:\n",
    "            test_loss, test_acc = model_eval(\n",
    "                model=model,\n",
    "                device=device,\n",
    "                loader=test_loader,\n",
    "            )\n",
    "\n",
    "            test_loss_list.append(test_loss)\n",
    "            test_acc_list.append(test_acc)\n",
    "\n",
    "    history = {\n",
    "        \"train loss\": train_loss_list,\n",
    "        \"train acc\": train_acc_list,\n",
    "    }\n",
    "    if needs_test_evaluation:\n",
    "        history.update({\n",
    "            \"test loss\": test_loss_list,\n",
    "            \"test acc\": test_acc_list,\n",
    "        })\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c835be2a5c43322"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Costume conv block"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0e6159744e9321"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_chan, out_chan, kernel=(3,3), stride=(1,1), padding=(1,1)):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_chan, out_channels=out_chan, kernel_size=kernel, padding=padding, stride=stride),\n",
    "            nn.BatchNorm2d(out_chan),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b447b938792034f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AlexNet model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f79732b8cdaa9ab2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            ConvBlock(in_chan=in_channel, out_chan=16, kernel=(9,9)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            ConvBlock(in_chan=16, out_chan=32, kernel=(7,7)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "\n",
    "            ConvBlock(in_chan=32, out_chan=64, kernel=(5,5)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            ConvBlock(in_chan=64, out_chan=128, kernel=(3, 3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            ConvBlock(in_chan=128, out_chan=128, kernel=(3,3)),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            \n",
    "            nn.Linear(in_features=1024, out_features=num_classes),\n",
    "        )\n",
    "        \n",
    "        self.av_net = nn.Linear(num_classes, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return nn.Softmax(self.network(x))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebd16f65e6f6da0e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "59ed5b4bdffc42dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "39a6d76d259a215a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Tune models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a0afa1c89c1c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AlexNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c05f7efc740cf31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2a4de2ed0c69d07"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a82db6b80d279afe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
