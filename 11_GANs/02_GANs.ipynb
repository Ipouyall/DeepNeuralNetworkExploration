{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing libraries and loading the dataset"
   ],
   "metadata": {
    "id": "22AC64tGw9fj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pytorch-fid -q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "2vRIytfJwdOt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "latent_dim = 64\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "3kTH2K66wm07"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "id": "FubQ7gGMPo8E"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset[0][0].shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gh-3xfZ4Q1DR",
    "outputId": "139b73eb-358e-459e-f419-d8ce0fa0073d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FID Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "TOTAL_SAMPLES = 5000\n",
    "ORIGINAL_DIR = 'original_samples'\n",
    "GENERATED_DIR = 'generated_samples'\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "test_indices = np.random.choice(len(test_dataset), TOTAL_SAMPLES, replace=False)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "fid_test_dataloader = DataLoader(test_dataset, batch_size=1, sampler=test_sampler)\n",
    "\n",
    "if os.path.exists(ORIGINAL_DIR):\n",
    "    shutil.rmtree(ORIGINAL_DIR)\n",
    "os.mkdir(ORIGINAL_DIR)\n",
    "\n",
    "for i, batch in enumerate(fid_test_dataloader):\n",
    "    path = f'test_{i}.png'\n",
    "    image = batch[0][0] * 255\n",
    "    image = to_pil(image.byte())\n",
    "    path = os.path.join(ORIGINAL_DIR, path)\n",
    "    image.save(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_fid_samples(model):\n",
    "    if os.path.exists(GENERATED_DIR):\n",
    "        shutil.rmtree(GENERATED_DIR)\n",
    "    os.mkdir(GENERATED_DIR)\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(fid_test_dataloader):\n",
    "        path = f'test_{i}.png'\n",
    "        batch = batch.to(device)\n",
    "        x_hat, *_ = model(batch)\n",
    "        x_hat = torch.round(x_hat)\n",
    "        image = x_hat[0][0] * 255\n",
    "        image = to_pil(image.byte())\n",
    "        path = os.path.join(GENERATED_DIR, path)\n",
    "        image.save(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_fid import fid_score as FID\n",
    "\n",
    "def calculate_fid(model):\n",
    "    save_fid_samples(model)\n",
    "    fid_score = FID.calculate_fid_given_paths([ORIGINAL_DIR, GENERATED_DIR], batch_size=batch_size, device=device, dims=2048)\n",
    "    return fid_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Defining discriminator and generator classes for GAN**"
   ],
   "metadata": {
    "id": "dIgzBFsaxd8Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(64, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 16*196),\n",
    "            nn.BatchNorm1d(16*196),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Unflatten(1, (16*196, 1, 1)),\n",
    "            nn.PixelShuffle(14),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.Conv2d(8, 1, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "metadata": {
    "id": "a8PPzUiLQmpJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#testing if the structure is OK\n",
    "x = torch.randn(4, 1, 28, 28)\n",
    "dis = Discriminator()\n",
    "result = dis(x)"
   ],
   "metadata": {
    "id": "9jfDvSgD3qWM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKKBFvjV4qNp",
    "outputId": "064ad527-957e-4a1c-b4ab-1e3258541ab1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZ-dDDOn4KFL",
    "outputId": "52e2a7d4-096b-41f7-c685-45abbe807ebd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "z = torch.randn(4, 64)\n",
    "generator = Generator()\n",
    "fake = generator(z)"
   ],
   "metadata": {
    "id": "NI1A7n4gKOws"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fake.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVzoL62iw_ar",
    "outputId": "1078dbe8-e552-4f90-a088-e9c39badfaf4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training the GAN**"
   ],
   "metadata": {
    "id": "g3St-NCixopt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_and_plot_images(generator):\n",
    "    generator.eval()\n",
    "    z = torch.randn(25, latent_dim).to(device)\n",
    "    generated_images = generator(z).detach().cpu().numpy()\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for j in range(25):\n",
    "        plt.subplot(5, 5, j+1)\n",
    "        plt.imshow(generated_images[j, 0, :, :], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "generator_gan = Generator().to(device)\n",
    "discriminator_gan = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator_gan.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator_gan.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCELoss()"
   ],
   "metadata": {
    "id": "30030WwNP1mD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "losses_G = []\n",
    "losses_D = []\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        optimizer_D.zero_grad()\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        #We add the sigmoid layer here cause normal GAN ends with a sigmoid.\n",
    "        #But as the structure for WGAN for next part is the same as GAN we just won't add the sigmoid layer.\n",
    "        real_output = torch.sigmoid(discriminator_gan(real_images))\n",
    "        loss_real = criterion(real_output, real_labels)\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator_gan(z)\n",
    "        fake_output = torch.sigmoid(discriminator_gan(fake_images.detach()))\n",
    "        loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Discriminator loss\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Training Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_output = torch.sigmoid(discriminator_gan(fake_images))\n",
    "        loss_G = criterion(fake_output, real_labels)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        #printing generator and discriminator losses every 500 steps in one epoch\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \"\n",
    "                  f\"Discriminator Loss: {loss_D.item():.4f}, Generator Loss: {loss_G.item():.4f}\")\n",
    "\n",
    "    losses_G.append(loss_G.item())\n",
    "    losses_D.append(loss_D.item())\n",
    "\n",
    "    #show generated images in the beginning and middle of training\n",
    "    if (epoch == 0) or (epoch == epochs/2):\n",
    "        generate_and_plot_images(generator_gan)"
   ],
   "metadata": {
    "id": "R0tbhcf-P8va",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "9301e609-8572-4f84-fa68-3b90391dfd2f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(losses_G, losses_D):\n",
    "    plt.plot(losses_G, label='Generator Loss')\n",
    "    plt.plot(losses_D, label='Discriminator Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Generator and Discriminator Losses')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_loss(losses_G, losses_D)"
   ],
   "metadata": {
    "id": "vwN1gIBBa2S3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "outputId": "84ce8242-6bb7-44e0-e8f7-f2bfa38560fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#showing generated images after training\n",
    "generate_and_plot_images(generator_gan)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "kE9fSPhcDyAJ",
    "outputId": "d4185d7d-19ab-4592-bfdd-6fce1177f3cb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Validating our GAN**"
   ],
   "metadata": {
    "id": "HrisBK1kyE6b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fid_value = calculate_fid(generator_gan)\n",
    "print(f\"FID Score: {fid_value}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "LR09DIexyJrf",
    "outputId": "295fdc94-9f0e-4d27-8ed0-544386f5b165"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training the WGAN**"
   ],
   "metadata": {
    "id": "KAFKISK7XMZl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The WGAN has the previous arcitecture so we don't define new classes."
   ],
   "metadata": {
    "id": "FfexPKyd7RnN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "generator_wgan = Generator().to(device)\n",
    "discriminator_wgan = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = optim.Adam(generator_wgan.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator_wgan.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "#We use torch.mean for loss"
   ],
   "metadata": {
    "id": "bNdTJZ177aIb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "losses_G = []\n",
    "losses_D = []\n",
    "clip_value = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        real_output = discriminator_wgan(real_images)\n",
    "        loss_real = -torch.mean(real_output)\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator_wgan(z)\n",
    "        fake_output = discriminator_wgan(fake_images.detach())\n",
    "        loss_fake = torch.mean(fake_output)\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Clip weights of the critic\n",
    "        for p in discriminator_wgan.parameters():\n",
    "            p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_output = discriminator_wgan(fake_images)\n",
    "        loss_G = -torch.mean(fake_output)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \"\n",
    "                  f\"Discriminator Loss: {loss_D.item():.4f}, Generator Loss: {loss_G.item():.4f}\")\n",
    "\n",
    "    losses_G.append(loss_G.item())\n",
    "    losses_D.append(loss_D.item())\n",
    "\n",
    "    if (epoch == 0) or (epoch == epochs/2):\n",
    "        generate_and_plot_images(generator_wgan)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QnUFvCLbKZLT",
    "outputId": "3d6c3ab7-7f72-4230-8658-fe9a55b68ade"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_loss(losses_G, losses_D)"
   ],
   "metadata": {
    "id": "jfQAgZvvYAcm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "outputId": "aecee0f1-ad29-4eac-c273-c982bd20cc08"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generate_and_plot_images(generator_wgan)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "O0_FI521PuzO",
    "outputId": "39b6cdba-5e22-42a5-d9f4-ab018a76e9eb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Validating the WGAN**"
   ],
   "metadata": {
    "id": "EoOKOYF_XVQx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fid_value = calculate_fid(generator_wgan)\n",
    "print(f\"FID Score: {fid_value}\")"
   ],
   "metadata": {
    "id": "i7vdhgm3a61W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Defining the SSGAN**"
   ],
   "metadata": {
    "id": "0k7bLn_7XZgy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ResidualBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block1(x)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class ResidualBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock2, self).__init__()\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Downsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Downsample(scale_factor=2, mode='nearest')\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block2(x)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class SSGAN_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSGAN_Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(128, 256*4*4),\n",
    "            nn.BatchNorm1d(256*4*4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            ResidualBlock1(256, 256),\n",
    "            ResidualBlock1(256, 256),\n",
    "            ResidualBlock1(256, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        #return self.model(z.view(z.size(0), -1, 1, 1))\n",
    "        return self.model(z)\n",
    "\n",
    "class SSGAN_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SSGAN_Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            ResidualBlock2(1, 128),\n",
    "            ResidualBlock2(128, 128),\n",
    "            ResidualBlock2(128, 128),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "id": "oLtPXhl3XdUz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training the SSGAN**"
   ],
   "metadata": {
    "id": "je4QRbC0Xj17"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "\n",
    "generator_ssgan = SSGAN_Generator().to(device)\n",
    "discriminator_ssgan = SSGAN_Discriminator().to(device)\n",
    "\n",
    "optimizer_G_ss = optim.Adam(generator_ssgan.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_ss = optim.Adam(discriminator_ssgan.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_BCE = nn.BCEWithLogitsLoss()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "18la6Fj7-z62",
    "outputId": "e5ccb26d-ed87-436f-f38d-798b7cfc6c1a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "losses_G = []\n",
    "losses_D = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Training Discriminator\n",
    "        optimizer_D_ss.zero_grad()\n",
    "\n",
    "        real_output = discriminator_ssgan(real_images)\n",
    "        loss_real = criterion_BCE(real_output, torch.ones_like(real_output).to(device))\n",
    "\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_images = generator_ssgan(z)\n",
    "        fake_output = discriminator_ssgan(fake_images.detach())\n",
    "        loss_fake = criterion_BCE(fake_output, torch.zeros_like(fake_output).to(device))\n",
    "\n",
    "        # Rotation-based loss for the discriminator\n",
    "        #rotated_images = torch.rot90(real_images, k=1, dims=(2, 3))\n",
    "        rotated_images = torch.rot90(real_images.cpu(), k=1, dims=(2, 3)).to(device)\n",
    "        prob_rotation = discriminator_ssgan(rotated_images)\n",
    "        loss_rotation_D = -beta * torch.mean(prob_rotation)\n",
    "\n",
    "        # Discriminator loss\n",
    "        loss_D = loss_real + loss_fake + loss_rotation_D\n",
    "        loss_D.backward()\n",
    "        optimizer_D_ss.step()\n",
    "\n",
    "        # Training Generator\n",
    "        optimizer_G_ss.zero_grad()\n",
    "        fake_output = discriminator_ssgan(fake_images)\n",
    "        loss_G = criterion_BCE(fake_output, torch.ones_like(fake_output).to(device))\n",
    "\n",
    "        # Rotation-based loss for the generator\n",
    "        prob_rotation_gen = discriminator_ssgan(torch.rot90(fake_images, k=1, dims=(2, 3)))\n",
    "        loss_rotation_G = alpha * torch.mean(prob_rotation_gen)\n",
    "\n",
    "        # Generator loss\n",
    "        loss_G_total = loss_G + loss_rotation_G\n",
    "        loss_G_total.backward()\n",
    "        optimizer_G_ss.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader)}], \"\n",
    "                  f\"Discriminator Loss: {loss_D.item():.4f}, Generator Loss: {loss_G.item():.4f}\")\n",
    "\n",
    "    losses_G.append(loss_G.item())\n",
    "    losses_D.append(loss_D.item())\n",
    "\n",
    "    if (epoch == 0) or (epoch == epochs/2):\n",
    "        generate_and_plot_images(generator_ssgan)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "xVP2d3lbXmwA",
    "outputId": "2829a9d7-4c63-43ef-efba-f46cb21c5cb4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot losses_G and losses_D after training\n",
    "plot_loss(losses_G, losses_D)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "iOSY99EcX3Yx",
    "outputId": "8bb48bdf-0a93-4c9f-f8ce-0f864331ab0e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Show generated images after training\n",
    "generate_and_plot_images(generator_ssgan)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "TOdhd3NeYEee",
    "outputId": "e19c5a5b-7041-402c-a994-0c80ec1de186"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fid_value = calculate_fid(generator_ssgan)\n",
    "print(f\"FID Score: {fid_value}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "DrAc5OETYI7h",
    "outputId": "d0e0d4d6-6f2c-46ed-8365-73199852f8ff"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
